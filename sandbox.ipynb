{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandbox\n",
    "For testing and developing new Cyber Security Assessment tools in an interactive and persistent development environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import math\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats.distributions as distr\n",
    "import seaborn as sns\n",
    "\n",
    "from cyber import Defence, CommmonDefences, CyberComponent\n",
    "from tree import TreeNode, Link\n",
    "from comm_network import Aggregator, Device, CommNetwork\n",
    "from comm_network import LevelOfRedundancy\n",
    "from attackers import RandomAttacker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procedural Generation\n",
    "### Abstract Tree\n",
    "Consists of Devices and Aggregators. \n",
    "* Aggregators (internal nodes) require a **Hard** amount of effort to compromise and have a 50% chance of being compromised if the necessary effort is spent\n",
    "* Devices (leaf nodes) require an **Easy** amount of effort to compromise and also have a 50% chance of being compromised if the necesssary effort is spent\n",
    "* Control Center (root node) is **Very Hard** to compromise\n",
    "\n",
    "Controllable parameters include:\n",
    "* Number of devices (leaf nodes)\n",
    "* Number of Entrypoints (points where cyberattacks can originate)\n",
    "* Level of Redundancy (number of children per parent node)\n",
    "* Random deviation in Redundancy\n",
    "* Sibling to Sibling communication (lateral edges between nodes on the same level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = np.random.randint(low=0, high=52600)\n",
    "seed = 27194\n",
    "print(f\"Seed: {seed}\")\n",
    "np.random.seed(seed)\n",
    "pcn = CommNetwork(n_devices=15, n_entrypoints=1, redundancy=2, redundancy_deviation=1, enable_sibling_to_sibling_comm=True)\n",
    "root = pcn.root\n",
    "print(CommNetwork.show_tree(root))\n",
    "tree = pcn.graph\n",
    "print(f\"Number of Components: {pcn.n_components}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte Carlo\n",
    "Build an approximate profile of the network's cyber security by launching many cyber attacks. The higher N_ATTACKS the more precise the resulting distribution is, however this comes at the cost of increased computation time.\n",
    "The more nodes are compromised, the more successful the attack."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Active Graph Only\n",
    "Only perform Monte Carlo simulation on the currently active network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ATTACKS = 1000\n",
    "BUDGET = 5200\n",
    "compromised_array = np.zeros(shape=N_ATTACKS, dtype=np.int16)\n",
    "effort_array = np.zeros(shape=N_ATTACKS, dtype=np.float32)\n",
    "for attack_no in range(N_ATTACKS):\n",
    "    attacker = RandomAttacker(budget=BUDGET, verbose=False)\n",
    "    nodes_compromised, total_effort_spent = attacker.attack_network(pcn)\n",
    "    # print(f\"Nodes Compromised: {[n.id for n in nodes_compromised]} ({len(nodes_compromised)})\")\n",
    "    compromised_array[attack_no] = len([n for n in nodes_compromised if isinstance(n, Device)])\n",
    "    effort_array[attack_no] = total_effort_spent\n",
    "    pcn.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(8,6))\n",
    "fig.suptitle(f\"Budget: {BUDGET}, No. of Components: {pcn.n_components}, No. of Entrypoints: {pcn.n_entrypoints}\")\n",
    "sns.histplot(compromised_array, discrete=True, stat=\"probability\", ax=axes[0])\n",
    "axes[0].set(xticks=np.arange(0, len(pcn.graph.nodes())), xlabel=\"No. of Devices Compromised\")\n",
    "sns.histplot(effort_array, binwidth=1, ax=axes[1])\n",
    "axes[1].set(xlabel=\"Effort Spent\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Varied Parameter\n",
    "Perform monte carlo simulation while varying particular parameter, such as the level of redundancy in the network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ATTACKS = 1000\n",
    "N_DEVICES = 30\n",
    "BUDGET = 52\n",
    "SEED = np.random.randint(low=0, high=52600)\n",
    "N_ENTRYPOINTS = 1 # Total budget is multiplied by this!\n",
    "MIN_REDUNDANCY = 2\n",
    "MAX_REDUNDANCY = N_DEVICES\n",
    "REDUNDANCY_STEP = 2\n",
    "REDUNDANCY_DEVIATION = 1\n",
    "redundancies = np.arange(MIN_REDUNDANCY, MAX_REDUNDANCY, REDUNDANCY_STEP)\n",
    "\n",
    "print(f\"Seed: {SEED}\")\n",
    "np.random.seed(SEED)\n",
    "\n",
    "compromised_array = np.zeros(shape=(N_ATTACKS, len(redundancies)), dtype=np.int16)\n",
    "effort_array = np.zeros(shape=(N_ATTACKS, len(redundancies)), dtype=np.float32)\n",
    "for i, redundancy in enumerate(redundancies):\n",
    "    print(\"Redundancy:\", redundancy)\n",
    "    pcn = CommNetwork(n_devices=N_DEVICES,\n",
    "                      n_entrypoints=N_ENTRYPOINTS,\n",
    "                      redundancy=redundancy,\n",
    "                      redundancy_deviation=REDUNDANCY_DEVIATION,\n",
    "                      enable_sibling_to_sibling_comm=True)\n",
    "    # budget = budget_per_device*no_of_devices\n",
    "    for attack_no in range(N_ATTACKS):\n",
    "        attacker = RandomAttacker(budget=BUDGET, verbose=False)\n",
    "        nodes_compromised, total_effort_spent = attacker.attack_network(pcn)\n",
    "        compromised_array[attack_no, i] = len(nodes_compromised)\n",
    "        effort_array[attack_no, i] = total_effort_spent\n",
    "        pcn.reset()\n",
    "print({k:v for k,v in zip(*np.unique(compromised_array, return_counts=True))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(compromised_array, columns=redundancies)\n",
    "df = df.melt(var_name='Redundancy')\n",
    "\n",
    "display(df)\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8,6))\n",
    "sns.histplot(df, x=\"value\", hue=\"Redundancy\", discrete=True, ax=ax)\n",
    "sns.move_legend(ax, \"upper right\", ncols=4, title=\"Redundancy\")\n",
    "ax.set(xlabel=\"No. of Devices Compromised\", ylabel=\"Count\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "Plot the structure of the communication network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hierarchy_pos(G:nx.DiGraph, root:TreeNode, width:float=1., vert_gap:float=0.2, vert_loc:float=0, xcenter:float=0.5):\n",
    "\n",
    "    '''\n",
    "    Credit: Joel (https://stackoverflow.com/a/29597209/2966723) \n",
    "    Licensed under CC Attribution-Share Alike \n",
    "    \n",
    "    \n",
    "    If the graph is a tree this will return the positions to plot this in a \n",
    "    hierarchical layout.\n",
    "    \n",
    "    G (networkx.DiGraph): Graph (must be a tree)\n",
    "    root (Node): Root node of current graph\n",
    "    width (float): Horizontal space allocated for this branch - avoids overlap with other branches. Defaults to 1.0\n",
    "    vert_gap (float): Gap between levels of hierarchy. Defaults to 0.2\n",
    "    vert_loc (float): Vertical location of root. Defaults to 0.0\n",
    "    xcenter (float): Horizontal location of root. Defaults to 0.5\n",
    "    '''\n",
    "    # if not nx.is_tree(G):\n",
    "    #     raise TypeError('cannot use hierarchy_pos on a graph that is not a tree')\n",
    "\n",
    "    if root is None:\n",
    "        if isinstance(G, nx.DiGraph):\n",
    "            root = next(iter(nx.topological_sort(G)))  #allows back compatibility with nx version 1.11\n",
    "        else:\n",
    "            root = np.random.choice(list(G.nodes))\n",
    "\n",
    "    def _hierarchy_pos(G, root, width=1., vert_gap = 0.2, vert_loc = 0, xcenter = 0.5, pos = None, parent = None):\n",
    "        '''\n",
    "        see hierarchy_pos docstring for most arguments\n",
    "\n",
    "        pos: a dict saying where all nodes go if they have been assigned\n",
    "        parent: parent of this branch. - only affects it if non-directed\n",
    "\n",
    "        '''\n",
    "    \n",
    "        if pos is None:\n",
    "            pos = {root:(xcenter,vert_loc)}\n",
    "        else:\n",
    "            pos[root] = (xcenter, vert_loc)\n",
    "        children = root.children # list(G.neighbors(root))\n",
    "        if not isinstance(G, nx.DiGraph) and parent is not None:\n",
    "            for child in children:\n",
    "                child.remove_parents(parent)  \n",
    "        if len(children) !=0:\n",
    "            dx = width/len(children) \n",
    "            nextx = xcenter - width/2 - dx/2\n",
    "            for child in sorted(children, key=lambda child:child.id):\n",
    "                nextx += dx\n",
    "                pos = _hierarchy_pos(G,child, width = dx, vert_gap = vert_gap, \n",
    "                                    vert_loc = vert_loc-vert_gap, xcenter=nextx,\n",
    "                                    pos=pos, parent = root)\n",
    "        return pos\n",
    "\n",
    "            \n",
    "    return _hierarchy_pos(G, root, width, vert_gap, vert_loc, xcenter)\n",
    "\n",
    "node_color_mask = np.full(tree.number_of_nodes(), fill_value=\"#1f78b4\", dtype=object)\n",
    "node_edge_color_mask = np.full(tree.number_of_nodes(), fill_value=\"#000000\", dtype=object)\n",
    "edge_color_mask = np.full(tree.number_of_edges(), fill_value=\"#000000\", dtype=object)\n",
    "node_shape_mask = np.full(tree.number_of_nodes(), fill_value=\"s\", dtype=object)\n",
    "root_idx = None\n",
    "for i, node in enumerate(tree.nodes()):\n",
    "    if node.is_leaf:\n",
    "        # Dark Green if the Leaf Node (Device) is an entry point\n",
    "        node_color_mask[i] = \"green\" if node.is_accessible else \"lightgreen\"\n",
    "    else:\n",
    "        # Dark Blue if the Internal Node (Aggregator) is an entry point\n",
    "        node_color_mask[i] = \"#1f78b4\" if node.is_accessible else \"#1f98ff\"\n",
    "    # If the Node has no parent, it is the root of the Tree (the control center)\n",
    "    if len(node.parents) == 0:\n",
    "        root_idx = i\n",
    "        node_color_mask[i] = \"coral\"\n",
    "    if node.is_compromised:\n",
    "        # Compromised/hacked nodes have a red outline around them\n",
    "        node_edge_color_mask[i] = \"#ff0000\"\n",
    "\n",
    "for j, (start_node, end_node) in enumerate(tree.edges()):\n",
    "    # Edges / Communication Channels between 2 compromised nodes are compromised\n",
    "    if start_node.is_compromised and end_node.is_compromised:\n",
    "        edge_color_mask[j] = \"#ff0000\"\n",
    "\n",
    "# >> Plotting <<\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2,  figsize=(24,6), width_ratios=[0.6, 0.4])\n",
    "label_map = {node:node.id for node in tree.nodes()}\n",
    "\n",
    "# Hierarchical / Tree Visualization of Communication Network\n",
    "tree_pos = hierarchy_pos(nx.to_undirected(tree), root)\n",
    "nx.draw_networkx_nodes(tree, pos=tree_pos, ax=axes[0],\n",
    "                       node_size=800, node_shape=\"s\", node_color=node_color_mask,\n",
    "                       linewidths=1.0, edgecolors=node_edge_color_mask)\n",
    "nx.draw_networkx_labels(tree, pos=tree_pos, labels=label_map, ax=axes[0], font_size=10)\n",
    "nx.draw_networkx_edges(tree, pos=tree_pos, ax=axes[0], edge_color=edge_color_mask)\n",
    "\n",
    "# Spring Visualization of Communication Network\n",
    "spring_pos = nx.layout.spring_layout(tree)\n",
    "nx.draw_networkx_nodes(tree, pos=spring_pos, ax=axes[1],\n",
    "                       node_size=400, node_shape=\"s\", node_color=node_color_mask, \n",
    "                       linewidths=1.0, edgecolors=node_edge_color_mask, )\n",
    "nx.draw_networkx_labels(tree, pos=spring_pos, labels=label_map, ax=axes[1], font_size=10)\n",
    "nx.draw_networkx_edges(tree, pos=spring_pos, ax=axes[1], edge_color=edge_color_mask)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static Analysis\n",
    "Given an infinite budget, breaksdown the probability of compromising components in the network. The resulting probabilities are exact (except for floating point precision issues) but do not scale well to larger communication networks (> 5 nodes). Useful as a static feature of a communication network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from fractions import Fraction\n",
    "# TODO: Account for probability of 0 devices being compromised\n",
    "\n",
    "def iterate_over_paths(path, prob, reachable_nodes={}, visited_nodes={}, id_to_node={}):\n",
    "    current_id = path[-1]\n",
    "    current_node = id_to_node[current_id]\n",
    "    visited_previously = current_id in visited_nodes\n",
    "    if not visited_previously:\n",
    "        visited_nodes[current_id] = None\n",
    "    \n",
    "    neighbouring_nodes = {k.id:None for k in current_node.get_neighbours()}\n",
    "    reachable_nodes.update(neighbouring_nodes)\n",
    "    reachable_nodes = {k:None for k in reachable_nodes if k not in visited_nodes}\n",
    "    success_prob = current_node.get_prob_to_compromise()\n",
    "    # If we fail, this path terminates\n",
    "    yield path, prob*(1-success_prob), True\n",
    "    if visited_previously:\n",
    "        return\n",
    "    n_reachable = len(reachable_nodes)\n",
    "    reachable_ids =  list(reachable_nodes.keys())\n",
    "    for reachable_node_id in reachable_ids:\n",
    "        yield from iterate_over_paths(path+[reachable_node_id], prob*success_prob*(1/n_reachable),\n",
    "                                      copy.copy(reachable_nodes), copy.copy(visited_nodes),\n",
    "                                      id_to_node=id_to_node)\n",
    "        \n",
    "    # No more nodes reachable (entire network compromised)\n",
    "    if len(reachable_nodes) == 0:\n",
    "        yield path, prob*success_prob, False\n",
    "def get_all_paths(graph):\n",
    "    n_nodes = len(graph.nodes())\n",
    "    id_to_node = {node.id:node for node in graph.nodes()}\n",
    "    start_ids = list(id_to_node.keys())\n",
    "    # Different starting locations\n",
    "    for start_node_id in start_ids:\n",
    "        yield from iterate_over_paths([start_node_id], prob=1/n_nodes,\n",
    "                                      reachable_nodes={}, visited_nodes={},\n",
    "                                      id_to_node=id_to_node)\n",
    "     \n",
    "sum_probs = 0.0\n",
    "n_probs = {}\n",
    "for path_no, (path, prob, ends_on_failure) in enumerate(get_all_paths(pcn.graph)):\n",
    "    print(f\"Path {path_no} :: Prob {str(Fraction(prob).limit_denominator()):<15} :: {'-'.join([str(node) for node in path])} :: {ends_on_failure}\")\n",
    "    if (len(path) > 1 and ends_on_failure) or (not ends_on_failure):\n",
    "        path_length = len(path) - 1 if ends_on_failure else len(path)\n",
    "        n_probs[path_length] = prob if path_length not in n_probs else n_probs[path_length] + prob\n",
    "    sum_probs += prob\n",
    "print(f\"No. of Paths: {path_no}. Sum of Probabilities: {sum_probs} ({Fraction(sum_probs).limit_denominator()})\")\n",
    "n_probs[0] = sum(n_probs.values()) # TODO: Verify this\n",
    "print(\"\\n\".join(f\"{k} devices: {v}\" for k,v in sorted(n_probs.items(),key=lambda item: item[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = nx.adjacency_matrix(pcn.graph, nodelist=sorted(pcn.graph.nodes(), key=lambda node: node.id)).todense()\n",
    "print(\"A\\n\", A)\n",
    "np.fill_diagonal(A, val=0)\n",
    "A2 = A@A\n",
    "np.fill_diagonal(A2, val=0)\n",
    "print(\"A^2\\n\", A2)\n",
    "A3 = A2@A\n",
    "np.fill_diagonal(A3, val=0)\n",
    "print(\"A^3\\n\", A3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_required = 0.0\n",
    "nodes = pcn.graph.nodes()\n",
    "node_probs = {}\n",
    "for node in nodes:\n",
    "    # print(node)\n",
    "    probability_to_compromise = 1.0\n",
    "    for defence_name, defence in node.defences.items():\n",
    "        expected_effort = defence.effort_distribution.expect()\n",
    "        time_required += expected_effort\n",
    "        # print(\"\\t\", defence_name)\n",
    "        probability_to_compromise *= defence.p\n",
    "    node_probs[node] = probability_to_compromise\n",
    "\n",
    "prob_to_compromise_n_devices = {}\n",
    "all_nodes = set(nodes)\n",
    "cumulative = 0.0\n",
    "for n_devices in range(pcn.n_components, 0, -1):\n",
    "    prob_to_compromise_n_devices[n_devices] = cumulative\n",
    "    for combination in itertools.combinations(nodes, n_devices):\n",
    "        probability_to_compromise = 1.0\n",
    "        combination = set(combination)\n",
    "        missing_nodes = all_nodes.difference(combination)\n",
    "        for node in combination:\n",
    "            probability_to_compromise *= node_probs[node]\n",
    "        for node in missing_nodes:\n",
    "            probability_to_compromise *= (1 - node_probs[node])\n",
    "        prob_to_compromise_n_devices[n_devices] += probability_to_compromise \n",
    "    print(f\"{n_devices} Devices: {prob_to_compromise_n_devices[n_devices]}\")\n",
    "    cumulative += prob_to_compromise_n_devices[n_devices]\n",
    "print(prob_to_compromise_n_devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the probability of compromising all components is the same,\n",
    "# we can use the Binomial distribution function\n",
    "# Takes: 12.6 µs\n",
    "N = pcn.n_components\n",
    "k = 2\n",
    "p = 0.5\n",
    "cumulative = 0.0\n",
    "for k in range(pcn.n_components, 0, -1):\n",
    "    prob = math.comb(N, k)*math.pow(p, k)*math.pow(1-p,N-k)\n",
    "    print(f\"{k} Devices: {cumulative + prob}\")\n",
    "    cumulative += prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats.distributions as distr\n",
    "distr_lookup = {\n",
    "    \"TruncNorm\": distr.truncnorm, # Continuous, loc=mean (float), scale=standard deviation (float)\n",
    "    \"Exponential\": distr.expon, # Continuous, scale = 1 / lambda (float)\n",
    "    \"Gamma\": distr.gamma, # Continuous, a = shape parameter (integer)\n",
    "    \"Bernoulli\": distr.bernoulli, # Discrete\n",
    "}\n",
    "n_attacks = 20\n",
    "is_successful = distr.bernoulli(0.5).rvs(size=n_attacks).astype(bool)\n",
    "time_taken = distr.expon(scale=0.0).rvs(size=n_attacks)[is_successful]\n",
    "print(f\"Successful Attacks {sum(is_successful)}/{n_attacks}\\nTime Taken per Successful Attack: {time_taken}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Communication Network Specifications\n",
    "Explores how we can supply structured information to our procedural network generation algorithm. Includes information such as the types of components and defences we expect to see in the communication network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'device': [{'name': 'Meter',\n",
       "   'is_sensor': True,\n",
       "   'is_controller': False,\n",
       "   'is_autonomous': False,\n",
       "   'defences': [{'name': 'Defence',\n",
       "     'p': 0.2,\n",
       "     'effort': {'distr': 'expon', 'scale': 10, 'loc': 0}}],\n",
       "   'vulnerabilities': []},\n",
       "  {'name': 'Smart Meter',\n",
       "   'is_sensor': True,\n",
       "   'is_controller': True,\n",
       "   'is_autonomous': False,\n",
       "   'defences': [{'name': 'Defence',\n",
       "     'p': 0.3,\n",
       "     'effort': {'distr': 'expon', 'scale': 5, 'loc': 0}}],\n",
       "   'vulnerabilities': []}],\n",
       " 'aggregator': {'name': 'Concentrator',\n",
       "  'is_accessible': False,\n",
       "  'defences': [{'name': 'Defence',\n",
       "    'p': 0.1,\n",
       "    'effort': {'distr': 'expon', 'scale': 10, 'loc': 0}}],\n",
       "  'vulnerabilities': []},\n",
       " 'root': {'name': 'Operation Center',\n",
       "  'is_accessible': False,\n",
       "  'defences': [{'name': 'Defence',\n",
       "    'p': 0.01,\n",
       "    'effort': {'distr': 'expon', 'scale': 100, 'loc': 0}}],\n",
       "  'vulnerabilities': []}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "json.loads(\n",
    "\"\"\"{\n",
    "    \"device\": [\n",
    "        {\"name\": \"Meter\",\n",
    "         \"is_sensor\": true,\n",
    "         \"is_controller\": false,\n",
    "         \"is_autonomous\": false,\n",
    "         \"defences\": [\n",
    "            {\n",
    "                \"name\": \"Defence\",\n",
    "                \"p\": 0.2,\n",
    "                \"effort\": {\n",
    "                    \"distr\": \"expon\",\n",
    "                    \"scale\": 10,\n",
    "                    \"loc\": 0\n",
    "                }\n",
    "            }\n",
    "         ],\n",
    "         \"vulnerabilities\": []\n",
    "        },\n",
    "        {\"name\": \"Smart Meter\",\n",
    "         \"is_sensor\": true,\n",
    "         \"is_controller\": true,\n",
    "         \"is_autonomous\": false,\n",
    "         \"defences\": [\n",
    "            {\n",
    "                \"name\": \"Defence\",\n",
    "                \"p\": 0.3,\n",
    "                \"effort\": {\n",
    "                    \"distr\": \"expon\",\n",
    "                    \"scale\": 5,\n",
    "                    \"loc\": 0\n",
    "                }\n",
    "            }\n",
    "            \n",
    "         ],\n",
    "         \"vulnerabilities\": []\n",
    "        }\n",
    "    ],\n",
    "        \n",
    "    \"aggregator\": {\n",
    "        \"name\": \"Concentrator\",\n",
    "        \"is_accessible\": false,\n",
    "        \"defences\": [\n",
    "            {\n",
    "                \"name\": \"Defence\",\n",
    "                \"p\": 0.1,\n",
    "                \"effort\": {\n",
    "                    \"distr\": \"expon\",\n",
    "                    \"scale\": 10,\n",
    "                    \"loc\": 0\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "        \"vulnerabilities\": []\n",
    "    },\n",
    "\n",
    "    \"root\": {\n",
    "        \"name\": \"Operation Center\",\n",
    "        \"is_accessible\": false,\n",
    "        \"defences\": [\n",
    "            {\n",
    "                \"name\": \"Defence\",\n",
    "                \"p\": 0.01,\n",
    "                \"effort\": {\n",
    "                    \"distr\": \"expon\",\n",
    "                    \"scale\": 100,\n",
    "                    \"loc\": 0\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "        \"vulnerabilities\": []\n",
    "    }\n",
    "}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type bernoulli_gen is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Xavier\\Documents\\projects\\CyberElectricComms\\sandbox.ipynb Cell 22\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Xavier/Documents/projects/CyberElectricComms/sandbox.ipynb#X42sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstats\u001b[39;00m \u001b[39mimport\u001b[39;00m distributions \u001b[39mas\u001b[39;00m distr\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Xavier/Documents/projects/CyberElectricComms/sandbox.ipynb#X42sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m json\u001b[39m.\u001b[39;49mdumps(distr\u001b[39m.\u001b[39;49mbernoulli)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py:231\u001b[0m, in \u001b[0;36mdumps\u001b[1;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[39m# cached encoder\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mnot\u001b[39;00m skipkeys \u001b[39mand\u001b[39;00m ensure_ascii \u001b[39mand\u001b[39;00m\n\u001b[0;32m    228\u001b[0m     check_circular \u001b[39mand\u001b[39;00m allow_nan \u001b[39mand\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m indent \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m separators \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[0;32m    230\u001b[0m     default \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m sort_keys \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n\u001b[1;32m--> 231\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_encoder\u001b[39m.\u001b[39;49mencode(obj)\n\u001b[0;32m    232\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m JSONEncoder\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\encoder.py:200\u001b[0m, in \u001b[0;36mJSONEncoder.encode\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[39mreturn\u001b[39;00m encode_basestring(o)\n\u001b[0;32m    197\u001b[0m \u001b[39m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miterencode(o, _one_shot\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    201\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(chunks, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[0;32m    202\u001b[0m     chunks \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(chunks)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\encoder.py:258\u001b[0m, in \u001b[0;36mJSONEncoder.iterencode\u001b[1;34m(self, o, _one_shot)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    254\u001b[0m     _iterencode \u001b[39m=\u001b[39m _make_iterencode(\n\u001b[0;32m    255\u001b[0m         markers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefault, _encoder, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindent, floatstr,\n\u001b[0;32m    256\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkey_separator, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitem_separator, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msort_keys,\n\u001b[0;32m    257\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mskipkeys, _one_shot)\n\u001b[1;32m--> 258\u001b[0m \u001b[39mreturn\u001b[39;00m _iterencode(o, \u001b[39m0\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\encoder.py:180\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault\u001b[39m(\u001b[39mself\u001b[39m, o):\n\u001b[0;32m    162\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \u001b[39m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[39m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    178\u001b[0m \n\u001b[0;32m    179\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 180\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mObject of type \u001b[39m\u001b[39m{\u001b[39;00mo\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    181\u001b[0m                     \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mis not JSON serializable\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Object of type bernoulli_gen is not JSON serializable"
     ]
    }
   ],
   "source": [
    "class ComplexEncoder(json.JSONEncoder):\n",
    "\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, distr):\n",
    "            return [obj.real, obj.imag]\n",
    "        # Let the base class default method raise the TypeError\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "    \n",
    "from scipy.stats import distributions as distr\n",
    "json.dumps(distr.bernoulli, cls=ComplexEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
