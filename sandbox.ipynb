{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandbox\n",
    "For testing and developing new Cyber Security Assessment tools in an interactive and persistent development environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json\n",
    "import copy\n",
    "import random\n",
    "import warnings\n",
    "import math\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats.distributions as distr\n",
    "import seaborn as sns\n",
    "import pandapower\n",
    "from pathlib import Path as p\n",
    "\n",
    "from cyber.assets import Defence, Vulnerability, CommmonDefences, CyberDevice\n",
    "from communication.graph import CommNode, CommEdge\n",
    "from communication.network import Aggregator, Device, CommNetwork\n",
    "from attackers.random_attacker import RandomAttacker\n",
    "from cyber.analysis import Analyzer\n",
    "from visualization import plot_communication_network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procedural Generation\n",
    "### Abstract Tree\n",
    "Consists of Devices and Aggregators. \n",
    "* Aggregators (internal nodes) require a **Hard** amount of effort to compromise and have a 50% chance of being compromised if the necessary effort is spent\n",
    "* Devices (leaf nodes) require an **Easy** amount of effort to compromise and also have a 50% chance of being compromised if the necesssary effort is spent\n",
    "* Control Center (root node) is **Very Hard** to compromise\n",
    "\n",
    "Controllable parameters include:\n",
    "* Number of devices (leaf nodes)\n",
    "* Number of Entrypoints (points where cyberattacks can originate)\n",
    "* Number of children per parent node (inversely proportional to redundancy)\n",
    "* Random deviation in number of children\n",
    "* Sibling to Sibling communication (lateral edges between nodes on the same level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = np.random.randint(low=0, high=52600)\n",
    "np.random.seed(seed); random.seed(seed)\n",
    "print(f\"Seed: {np.random.get_state()[1][0]}\")\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(action=\"ignore\", category=FutureWarning)\n",
    "    grid=pandapower.networks.create_cigre_network_mv(with_der=\"all\")\n",
    "    print(grid)\n",
    "    pandapower.plotting.simple_plot(grid, plot_loads=True)\n",
    "    pcn = CommNetwork(n_devices=3, n_entrypoints=1, children_per_parent=0, child_no_deviation=5, \n",
    "                    network_specs=p.cwd() / \"specifications\" / \"SCADA_specifications.json\", \n",
    "                    # \"Default_specifications.json\", \"SmartMeter_specifications.json\", \"SCADA_specifications.json\", \"WAMS_specifications.json\"\n",
    "                    grid=grid,\n",
    "                    enable_sibling_to_sibling_comm=True)\n",
    "print(CommNetwork.show_tree(pcn.root))\n",
    "print(f\"Number of Components: {pcn.n_components}\")\n",
    "\n",
    "analyzer = Analyzer(pcn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from procedural.specification import SpecDecoder\n",
    "\n",
    "with open(p.cwd() / \"specifications\" / \"SmartMeter_specifications.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    specs = json.load(f, cls=SpecDecoder)\n",
    "prop = None\n",
    "n_devices = 10\n",
    "\n",
    "components = []\n",
    "\n",
    "cat_spec = specs[\"device\"][\"categories\"]\n",
    "cat_lookup = {cat[\"name\"]:cat for cat in cat_spec}\n",
    "categories = list(cat_lookup.keys())\n",
    "\n",
    "# Proportion of devices of each type (default: uniform)\n",
    "uniform_device_types = [1/len(categories)]*len(categories)\n",
    "device_type_prob = specs[\"device\"].get(\"proportion\", uniform_device_types) if prop is None else prop\n",
    "if grid is None: \n",
    "    # Device Type is based on statistic / expected proportion\n",
    "    device_population = np.random.choice(categories, p=device_type_prob, replace=True, size=n_devices)\n",
    "    device_map = [(i, cat_name, 1) for i, cat_name in enumerate(device_population)]\n",
    "else: \n",
    "    # Apply rules in Specifications to assign 1 or more devices to equipment in the grid.\n",
    "\n",
    "    # Map device category (by name) to probability that device is of that category\n",
    "    prob_lookup = {cat_name: prob for cat_name, prob in zip(categories, device_type_prob)}\n",
    "\n",
    "    compat = {}\n",
    "    for i, cat_name in enumerate(categories):\n",
    "        cat = cat_lookup[cat_name]\n",
    "        comp_devices = cat.get(\"compatible\")\n",
    "        for comp_device, conditions in comp_devices.items():\n",
    "            equip_df = getattr(grid, comp_device)\n",
    "\n",
    "            # DataFrame with probability of choosing each Device Category (e.g. different types of smart meters)\n",
    "            if comp_device not in compat:\n",
    "                compat[comp_device] = dict(\n",
    "                    probs=pd.DataFrame(np.zeros((equip_df.shape[0], len(categories))), columns=categories),\n",
    "                    splits=pd.DataFrame(np.zeros((equip_df.shape[0], len(categories))), columns=categories, dtype=np.int16),\n",
    "                )\n",
    "            # Find Equipment that meets Conditions\n",
    "            if \"filter\" in conditions:\n",
    "                condition = conditions[\"filter\"]\n",
    "                criteria = equip_df.get(condition[\"attribute\"])\n",
    "                mask = (criteria >= condition.get(\"lb\", -math.inf)) & \\\n",
    "                       (criteria <= condition.get(\"ub\",  math.inf))\n",
    "                compat[comp_device][\"probs\"].iloc[mask, i] = prob_lookup[cat_name]\n",
    "            else:\n",
    "                compat[comp_device][\"probs\"].iloc[:, i] = prob_lookup[cat_name]\n",
    "\n",
    "            if \"split\" in conditions:\n",
    "                condition = conditions[\"split\"]\n",
    "                criteria = equip_df.get(condition[\"attribute\"])\n",
    "                min_splits = criteria.floordiv(condition.get(\"limit\", math.inf)).astype(np.int16)\n",
    "                leftover_split = (criteria.mod(condition.get(\"limit\", math.inf)) > 0).astype(np.int16)\n",
    "                compat[comp_device][\"splits\"].iloc[:, i] = min_splits + leftover_split\n",
    "            \n",
    "    select_compatible_device_category = lambda p: np.random.choice(categories, p=p)\n",
    "    \n",
    "    no_of_devices = 0\n",
    "    device_map = []\n",
    "    for comp_device in compat.keys():\n",
    "        equip_df = getattr(grid, comp_device)\n",
    "\n",
    "        # Normalize probabilities (must sum to 1)\n",
    "        probs = compat[comp_device][\"probs\"]\n",
    "        probs = probs.div(probs.sum(axis=1), axis=0).dropna()\n",
    "\n",
    "        # Select device category\n",
    "        equip_df[\"Category\"] = probs.apply(select_compatible_device_category, axis=1)\n",
    "        equip_df.dropna(subset=[\"Category\"], inplace=True)\n",
    "\n",
    "        # Split device if equipment exceeds size limit\n",
    "        select_no_of_splits = lambda row: row[equip_df.Category.loc[row.name].item()]\n",
    "        equip_df[\"Splits\"] = compat[comp_device][\"splits\"].apply(select_no_of_splits, axis=1)\n",
    "        \n",
    "        device_map.extend([(i, equip_df.iloc[i, -2], equip_df.iloc[i, -1]) for i in range(equip_df.shape[0])])\n",
    "\n",
    "\n",
    "# Create Devices\n",
    "for i, cat_name, n_splits in device_map:\n",
    "    cat = cat_lookup[cat_name]\n",
    "    device_name = cat.get(\"name\", \"Device\")\n",
    "    device_attrs =  CommNetwork.get_binary_attributes(cat,\n",
    "                    [\"is_sensor\", \"is_controller\", \"is_accessible\", \"is_autonomous\"])\n",
    "    for j in range(n_splits):\n",
    "        device = Device(name=device_name,\n",
    "                        is_controller=device_attrs[\"is_controller\"],\n",
    "                        is_sensor=device_attrs[\"is_sensor\"],\n",
    "                        is_autonomous=device_attrs[\"is_autonomous\"],\n",
    "                        is_accessible=device_attrs[\"is_accessible\"],)\n",
    "        CommNetwork.attach_cyber_characteristics(device, cat)\n",
    "        components.append(device)\n",
    "        # self.node_ids.append(device.id)\n",
    "        # self.id_to_node[device.id] = device\n",
    "        # self.n_components += 1\n",
    "\n",
    "    # Find all equipment that is compatible with a specific device type\n",
    "    # If equipment is only compatible with that device type, assign it\n",
    "    # Otherwise, pick based on proportion\n",
    "\n",
    "   \n",
    "\n",
    "#     split_mask = criteria > condition.get(\"limit\")\n",
    "#     to_split, not_to_split = df[split_mask], df[~split_mask]\n",
    "#     for equip in not_to_split.name:\n",
    "#         compat[comp_device][equip].append(cat_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compat[\"bus\"].iloc[:, :] = np.random.random(compat[\"bus\"].shape)\n",
    "for comp_device in compat.keys():\n",
    "    compat[comp_device] = compat[comp_device].div(compat[comp_device].sum(axis=1), axis=0).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compat[\"bus\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.choice(compat[\"bus\"].columns, size=1, replace=True, p=compat[\"bus\"].iloc[0]).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "Plot the structure of the communication network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_communication_network(pcn, palette=\"tab10\") # \"tab10\" (default), \"Set2\", \"Paired\", \"flare\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monte Carlo\n",
    "Build an approximate profile of the network's cyber security by launching many cyber attacks. The higher N_ATTACKS the more precise the resulting distribution is, however this comes at the cost of increased computation time.\n",
    "The more nodes are compromised, the more successful the attack."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Active Graph Only\n",
    "Only perform Monte Carlo simulation on the currently active network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N_ATTACKS = 1000\n",
    "BUDGET = 52\n",
    "ATTACKER_VARIANT = RandomAttacker\n",
    "compromised_array, effort_array = analyzer.monte_carlo_analysis(n_attacks=N_ATTACKS, attacker_variant=ATTACKER_VARIANT, budget=BUDGET)\n",
    "analyzer.plot_monte()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Varied Parameter\n",
    "Perform monte carlo simulation while varying particular parameter, such as the level of redundancy in the network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocess as mp\n",
    "N_ATTACKS = 1000\n",
    "N_DEVICES = 30\n",
    "BUDGET = 52\n",
    "SPEC = p.cwd() / \"specifications\" / \"SmartMeter_specifications.json\" \n",
    "SEED = np.random.randint(low=0, high=52600)\n",
    "N_ENTRYPOINTS = 1 # Total budget is multiplied by this!\n",
    "MIN_CHILDREN = 2\n",
    "MAX_CHILDREN = N_DEVICES\n",
    "CHILD_NO_STEP = 2\n",
    "CHILD_NO_DEVIATION = 0\n",
    "no_of_children = np.arange(MIN_CHILDREN, MAX_CHILDREN, CHILD_NO_STEP)\n",
    "network_specs = dict(n_devices=N_DEVICES,\n",
    "                     n_entrypoints=N_ENTRYPOINTS,\n",
    "                     network_specs=SPEC,\n",
    "                     child_no_deviation=CHILD_NO_DEVIATION,\n",
    "                     enable_sibling_to_sibling_comm=True)\n",
    "\n",
    "compromised_array, effort_array = analyzer.monte_carlo_multi_analysis(seed, \"children_per_parent\", no_of_children, budget=BUDGET, n_attacks=N_ATTACKS, **network_specs)\n",
    "analyzer.plot_monte()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static Analysis\n",
    "Given an infinite budget, breaksdown the probability of compromising components in the network. The resulting probabilities are exact (except for floating point precision issues) but do not scale well to larger communication networks (> 5 nodes). Useful as a static feature of a communication network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_probs = analyzer.static_analysis(show_paths=False, verbose=True)\n",
    "analyzer.plot_static()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjacency Matrix\n",
    "# Does not handle self-loops / backtracking\n",
    "# Consequently, probabilities will differ from combinatorial approach\n",
    "\n",
    "def superscript(num:int):\n",
    "    sup_map = {0: f\"\\N{SUPERSCRIPT ZERO}\", 1: f\"\\N{SUPERSCRIPT ONE}\", 2: f\"\\N{SUPERSCRIPT TWO}\", 3: f\"\\N{SUPERSCRIPT THREE}\", 4: f\"\\N{SUPERSCRIPT FOUR}\", \n",
    "           5: f\"\\N{SUPERSCRIPT FIVE}\",  6: f\"\\N{SUPERSCRIPT SIX}\", 7: f\"\\N{SUPERSCRIPT SEVEN}\", 8: f\"\\N{SUPERSCRIPT EIGHT}\", 9: f\"\\N{SUPERSCRIPT NINE}\"}\n",
    "    return \"\".join(sup_map[digit] for digit in map(int, str(num)))\n",
    "\n",
    "np.set_printoptions(precision=2, floatmode=\"maxprec_equal\")\n",
    "nodes = sorted(pcn.graph.nodes(), key=lambda node: node.id)\n",
    "prob_lookup = [node.get_prob_to_compromise() for node in nodes]\n",
    "print(f\"Probabilities: {prob_lookup}\")\n",
    "\n",
    "\n",
    "A = nx.adjacency_matrix(pcn.graph, nodelist=nodes, weight=\"p\").todense()\n",
    "n_probs = {}\n",
    "oldA = np.eye(A.shape[0])\n",
    "for i in range(len(nodes)):\n",
    "    newA = oldA@A\n",
    "    # np.fill_diagonal(newA, val=0)\n",
    "    print(f\"A{superscript(i+1)}\\n\", newA)\n",
    "    n_probs[i+1] = np.triu(newA, k=1).sum()\n",
    "    print(f\"A{superscript(i+1)}: {n_probs[i+1]}\")\n",
    "    oldA = newA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mutually Exclusive Approach\n",
    "# Assumes you can jump and independently attack any node (i.e. ignores communication connections!)\n",
    "\n",
    "time_required = 0.0\n",
    "nodes = pcn.graph.nodes()\n",
    "node_probs = {node: node.get_prob_to_compromise() for node in nodes}\n",
    "\n",
    "n_probs = {}\n",
    "all_nodes = set(nodes)\n",
    "cumulative = 0.0\n",
    "for n_devices in range(pcn.n_components, 0, -1):\n",
    "    n_probs[n_devices] = cumulative\n",
    "    for combination in itertools.combinations(nodes, n_devices):\n",
    "        probability_to_compromise = 1.0\n",
    "        combination = set(combination)\n",
    "        missing_nodes = all_nodes.difference(combination)\n",
    "        for node in combination:\n",
    "            probability_to_compromise *= node_probs[node]\n",
    "        for node in missing_nodes:\n",
    "            probability_to_compromise *= (1 - node_probs[node])\n",
    "        n_probs[n_devices] += probability_to_compromise \n",
    "    cumulative += n_probs[n_devices]\n",
    "print(\"\\n\".join(f\"{k} devices: {v}\" for k,v in sorted(n_probs.items(), key=lambda item: item[0])))\n",
    "print(\"Sum:\", sum(n_probs.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the probability of compromising all components is the same,\n",
    "# we can use the Binomial distribution function\n",
    "# Takes: 12.6 Âµs\n",
    "N = pcn.n_components\n",
    "k = 2\n",
    "p = 0.5\n",
    "cumulative = 0.0\n",
    "for k in range(N, 0, -1):\n",
    "    prob = math.comb(N, k)*math.pow(p, k)*math.pow(1-p,N-k)\n",
    "    print(f\"{k} Devices: {cumulative + prob}\")\n",
    "    cumulative += prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats.distributions as distr\n",
    "distr_lookup = {\n",
    "    \"TruncNorm\": distr.truncnorm, # Continuous, loc=mean (float), scale=standard deviation (float)\n",
    "    \"Exponential\": distr.expon, # Continuous, scale = 1 / lambda (float)\n",
    "    \"Gamma\": distr.gamma, # Continuous, a = shape parameter (integer)\n",
    "    \"Bernoulli\": distr.bernoulli, # Discrete\n",
    "}\n",
    "n_attacks = 20\n",
    "is_successful = distr.bernoulli(0.5).rvs(size=n_attacks).astype(bool)\n",
    "time_taken = distr.expon(scale=0.0).rvs(size=n_attacks)[is_successful]\n",
    "print(f\"Successful Attacks {sum(is_successful)}/{n_attacks}\\nTime Taken per Successful Attack: {time_taken}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Communication Network Specifications\n",
    "Explores how we can supply structured information to our procedural network generation algorithm. Includes information such as the types of components and defences we expect to see in the communication network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed = np.random.randint(low=0, high=52600)\n",
    "seed = 27194\n",
    "print(f\"Seed: {seed}\")\n",
    "np.random.seed(seed)\n",
    "pcn = CommNetwork(n_devices=15, n_entrypoints=1, children_per_parent=5, child_no_deviation=1,\n",
    "                  network_specs=\"SmartMeterNetworkSpecifications.json\",\n",
    "                  enable_sibling_to_sibling_comm=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power System Component Association"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandapower as pp\n",
    "import pandapower.networks as grids\n",
    "grid = pp.create_empty_network()\n",
    "grid_filter = lambda module: inspect.isfunction(module) and not module.__name__.startswith(\"_\")\n",
    "grid_map = {grid_name:grid_creator for grid_name, grid_creator in \\\n",
    "            inspect.getmembers(grids, predicate=grid_filter)}\n",
    "grid_options = list(grid_map.keys())\n",
    "print(\", \".join(grid_map.keys()))\n",
    "CHOSEN_GRID = \"mv_oberrhein\" # \"create_cigre_network_mv\" # Can be None\n",
    "kwargs = dict(scenario=\"generation\", include_substations=True) #  dict(with_der=\"all\")\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(action=\"ignore\", category=FutureWarning)\n",
    "    grid_name = np.random.choice(grid_options) if CHOSEN_GRID is None else CHOSEN_GRID\n",
    "    print(f\"Grid: {grid_name}\")\n",
    "    grid = grid_map[grid_name](**kwargs)\n",
    "    print(grid)\n",
    "    # Controllable\n",
    "    n_controllable = sum(getattr(grid, attr).shape[0] for attr in [\"gen\", \"shunt\", \"trafo\", \"switch\"])\n",
    "    print(f\"No. of controllable elements: {n_controllable} (generators, shunts, transformers and switches)\")\n",
    "    # Sensor-Only\n",
    "    n_sensor_only = sum(getattr(grid, attr).shape[0] for attr in [\"bus\", \"load\", \"line\"])\n",
    "    print(f\"No. of sensor-only elements: {n_sensor_only} (buses, loads and lines)\")\n",
    "    print(f\"Total (possible) no. of devices: {n_sensor_only+n_controllable} (generators, shunts, transformers and switches, buses, loads and lines)\")\n",
    "\n",
    "# grid.switch.closed = True\n",
    "pp.plotting.simple_plot(grid, respect_switches=True, plot_line_switches=True, plot_loads=True, plot_gens=True, plot_sgens=True, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = np.random.randint(low=0, high=52600)\n",
    "np.random.seed(seed); random.seed(seed)\n",
    "print(f\"Seed: {np.random.get_state()[1][0]}\")\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(action=\"ignore\", category=FutureWarning)\n",
    "    grid = pandapower.networks.mv_oberrhein(scenario=\"generation\") # pandapower.networks.case14()\n",
    "    print(grid)\n",
    "    pcn = CommNetwork(n_devices=30, n_entrypoints=1, children_per_parent=0, child_no_deviation=5, \n",
    "                    network_specs=p.cwd() / \"specifications\" / \"SCADA_specifications.json\", \n",
    "                    # \"Default_specifications.json\", \"SmartMeter_specifications.json\", \"SCADA_specifications.json\", \"WAMS_specifications.json\"\n",
    "                    grid=grid,\n",
    "                    enable_sibling_to_sibling_comm=True)\n",
    "print(CommNetwork.show_tree(pcn.root))\n",
    "print(f\"Number of Components: {pcn.n_components}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
