{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandbox\n",
    "For testing and developing new Cyber Security Assessment tools in an interactive and persistent development environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json\n",
    "import copy\n",
    "import random\n",
    "import warnings\n",
    "import math\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats.distributions as distr\n",
    "import seaborn as sns\n",
    "import pandapower\n",
    "from pathlib import Path as p\n",
    "\n",
    "from cyber import Defence, Vulnerability, CommmonDefences, CyberComponent\n",
    "from tree import TreeNode, Link\n",
    "from comm_network import Aggregator, Device, CommNetwork\n",
    "from attackers import RandomAttacker\n",
    "from visualise import plot_communication_network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procedural Generation\n",
    "### Abstract Tree\n",
    "Consists of Devices and Aggregators. \n",
    "* Aggregators (internal nodes) require a **Hard** amount of effort to compromise and have a 50% chance of being compromised if the necessary effort is spent\n",
    "* Devices (leaf nodes) require an **Easy** amount of effort to compromise and also have a 50% chance of being compromised if the necesssary effort is spent\n",
    "* Control Center (root node) is **Very Hard** to compromise\n",
    "\n",
    "Controllable parameters include:\n",
    "* Number of devices (leaf nodes)\n",
    "* Number of Entrypoints (points where cyberattacks can originate)\n",
    "* Number of children per parent node (inversely proportional to redundancy)\n",
    "* Random deviation in number of children\n",
    "* Sibling to Sibling communication (lateral edges between nodes on the same level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = np.random.randint(low=0, high=52600)\n",
    "np.random.seed(seed); random.seed(seed)\n",
    "print(f\"Seed: {np.random.get_state()[1][0]}\")\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(action=\"ignore\", category=FutureWarning)\n",
    "    grid=pandapower.networks.case14()\n",
    "    print(grid)\n",
    "    pcn = CommNetwork(n_devices=30, n_entrypoints=1, children_per_parent=0, child_no_deviation=5, \n",
    "                    network_specs=p.cwd() / \"specifications\" / \"WAMS_specifications.json\", \n",
    "                    # \"Default_specifications.json\", \"SmartMeter_specifications.json\", \"SCADA_specifications.json\", \"WAMS_specifications.json\"\n",
    "                    grid=grid,\n",
    "                    enable_sibling_to_sibling_comm=True)\n",
    "print(CommNetwork.show_tree(pcn.root))\n",
    "print(f\"Number of Components: {pcn.n_components}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "Plot the structure of the communication network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_communication_network(pcn, palette=\"tab10\") # \"tab10\" (default), \"Set2\", \"Paired\", \"flare\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte Carlo\n",
    "Build an approximate profile of the network's cyber security by launching many cyber attacks. The higher N_ATTACKS the more precise the resulting distribution is, however this comes at the cost of increased computation time.\n",
    "The more nodes are compromised, the more successful the attack."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Active Graph Only\n",
    "Only perform Monte Carlo simulation on the currently active network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ATTACKS = 1000\n",
    "BUDGET = 52\n",
    "compromised_array = np.zeros(shape=N_ATTACKS, dtype=np.int16)\n",
    "effort_array = np.zeros(shape=N_ATTACKS, dtype=np.float32)\n",
    "for attack_no in range(N_ATTACKS):\n",
    "    attacker = RandomAttacker(budget=BUDGET, verbose=False)\n",
    "    nodes_compromised, total_effort_spent = attacker.attack_network(pcn)\n",
    "    compromised_array[attack_no] = len([n for n in nodes_compromised if isinstance(n, Device)])\n",
    "    effort_array[attack_no] = total_effort_spent\n",
    "    pcn.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(8,6))\n",
    "fig.suptitle(f\"Attacker: {attacker.__name__}, Budget: {BUDGET}\\nNetwork Size: {pcn.n_components}, No. of Devices: {pcn.n_devices}, No. of Entrypoints: {pcn.n_entrypoints}\", \n",
    "             y=-0.05, fontsize=\"medium\", ma=\"center\")\n",
    "sns.histplot(compromised_array, discrete=True, stat=\"probability\", ax=axes[0])\n",
    "axes[0].set(xticks=np.arange(0, len(pcn.graph.nodes())), xlabel=\"No. of Devices Compromised\")\n",
    "sns.histplot(effort_array, binwidth=1, ax=axes[1])\n",
    "axes[1].set(xlabel=\"Effort Spent\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Varied Parameter\n",
    "Perform monte carlo simulation while varying particular parameter, such as the level of redundancy in the network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocess as mp\n",
    "N_ATTACKS = 10000\n",
    "N_DEVICES = 30\n",
    "BUDGET = 52\n",
    "SPEC = p.cwd() / \"SmartMeterNetworkSpecifications.json\"\n",
    "SEED = np.random.randint(low=0, high=52600)\n",
    "N_ENTRYPOINTS = 1 # Total budget is multiplied by this!\n",
    "MIN_CHILDREN = 2\n",
    "MAX_CHILDREN = N_DEVICES\n",
    "CHILD_NO_STEP = 2\n",
    "CHILD_NO_DEVIATION = 0\n",
    "no_of_children = np.arange(MIN_CHILDREN, MAX_CHILDREN, CHILD_NO_STEP)\n",
    "network_specs = dict(n_devices=N_DEVICES,\n",
    "                     n_entrypoints=N_ENTRYPOINTS,\n",
    "                     network_specs=SPEC,\n",
    "                     child_no_deviation=CHILD_NO_DEVIATION,\n",
    "                     enable_sibling_to_sibling_comm=True)\n",
    "\n",
    "print(f\"Seed: {SEED}\")\n",
    "np.random.seed(SEED)\n",
    "\n",
    "compromised_array = np.zeros(shape=(N_ATTACKS, len(no_of_children)), dtype=np.int16)\n",
    "effort_array = np.zeros(shape=(N_ATTACKS, len(no_of_children)), dtype=np.float32)\n",
    "print(f\"CPU Thread Count: {mp.cpu_count()-2}\")\n",
    "\n",
    "def monte_carlo(process_idx, seed, n_attacks, budget, **network_kwargs):\n",
    "    import os\n",
    "    import numpy as np\n",
    "    from comm_network import CommNetwork, Device\n",
    "    from attackers import RandomAttacker\n",
    "    \n",
    "    # Procedurally generate a communication network with specific redundancy\n",
    "    np.random.seed(seed)\n",
    "    pcn = CommNetwork(**network_kwargs)\n",
    "\n",
    "    # Store effort and no. of devices compromised\n",
    "    compromised_array = np.zeros(shape=n_attacks, dtype=np.int16)\n",
    "    effort_array = np.zeros(shape=n_attacks, dtype=np.float32)\n",
    "\n",
    "    for attack_no in range(n_attacks):\n",
    "        attacker = RandomAttacker(budget=budget, verbose=False)\n",
    "        nodes_compromised, total_effort_spent = attacker.attack_network(pcn)\n",
    "        compromised_array[attack_no] = len([n for n in nodes_compromised if isinstance(n, Device)])\n",
    "        effort_array[attack_no] = total_effort_spent\n",
    "        # Entrypoint changes with each attack (i.e. same network different entrypoint)\n",
    "        pcn.reset() \n",
    "    return process_idx, compromised_array, effort_array\n",
    "\n",
    "with mp.Pool(processes=len(no_of_children)) as pool:\n",
    "    results = []\n",
    "    for i, children_per_parent in enumerate(no_of_children):\n",
    "        print(\"Children per parent:\", children_per_parent)\n",
    "        kwds = {**network_specs, **dict(children_per_parent=children_per_parent)}\n",
    "        results.append(\n",
    "            pool.apply_async(monte_carlo, args=[i, SEED, N_ATTACKS, BUDGET], kwds=kwds)\n",
    "        )\n",
    "    \n",
    "    for result in results:\n",
    "        process_idx, compromises, efforts = result.get()\n",
    "        compromised_array[:, process_idx] = compromises\n",
    "        effort_array[:, process_idx] = efforts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(compromised_array, columns=no_of_children)\n",
    "df = df.melt(var_name='Children')\n",
    "\n",
    "display(df)\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8,6))\n",
    "sns.histplot(df, x=\"value\", hue=\"Children\", discrete=True, stat=\"probability\", common_norm=False, ax=ax)\n",
    "sns.move_legend(ax, \"upper right\", ncols=4, title=\"Children per Parent\")\n",
    "ax.set(xlabel=\"No. of Devices Compromised\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static Analysis\n",
    "Given an infinite budget, breaksdown the probability of compromising components in the network. The resulting probabilities are exact (except for floating point precision issues) but do not scale well to larger communication networks (> 5 nodes). Useful as a static feature of a communication network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from fractions import Fraction\n",
    "import multiprocess as mp\n",
    "# TODO: Account for probability of 0 devices being compromised\n",
    "\n",
    "def iterate_over_paths(path, prob, reachable_nodes={}, visited_nodes={}, id_to_node={}):\n",
    "    current_id = path[-1]\n",
    "    current_node = id_to_node[current_id]\n",
    "    visited_previously = current_id in visited_nodes\n",
    "    if not visited_previously:\n",
    "        visited_nodes[current_id] = None\n",
    "    \n",
    "    neighbouring_nodes = {k.id:None for k in current_node.get_neighbours()}\n",
    "    reachable_nodes.update(neighbouring_nodes)\n",
    "    reachable_nodes = {k:None for k in reachable_nodes if k not in visited_nodes}\n",
    "    success_prob = current_node.get_prob_to_compromise()\n",
    "    # If we fail, this path terminates\n",
    "    yield path, prob*(1-success_prob), True\n",
    "    if visited_previously:\n",
    "        return\n",
    "    n_reachable = len(reachable_nodes)\n",
    "    reachable_ids =  list(reachable_nodes.keys())\n",
    "    for reachable_node_id in reachable_ids:\n",
    "        yield from iterate_over_paths(path+[reachable_node_id], prob*success_prob*(1/n_reachable),\n",
    "                                      copy.copy(reachable_nodes), copy.copy(visited_nodes),\n",
    "                                      id_to_node=id_to_node)\n",
    "        \n",
    "    # No more nodes reachable (entire network compromised)\n",
    "    if len(reachable_nodes) == 0:\n",
    "        yield path, prob*success_prob, False\n",
    "\n",
    "def get_all_paths(graph):\n",
    "    n_nodes = len(graph.nodes())\n",
    "    id_to_node = {node.id:node for node in graph.nodes()}\n",
    "    start_ids = list(id_to_node.keys())\n",
    "    # Different starting locations\n",
    "    for start_node_id in start_ids:\n",
    "        yield from iterate_over_paths([start_node_id], prob=1/n_nodes,\n",
    "                                      reachable_nodes={}, visited_nodes={},\n",
    "                                      id_to_node=id_to_node)\n",
    "     \n",
    "sum_probs = 0.0\n",
    "n_probs = {}\n",
    "for path_no, (path, prob, ends_on_failure) in enumerate(get_all_paths(pcn.graph)):\n",
    "    print(f\"Path {path_no} :: Prob {str(Fraction(prob).limit_denominator()):<15} :: {'-'.join([str(node) for node in path])} :: {ends_on_failure}\")\n",
    "    if (len(path) > 1 and ends_on_failure) or (not ends_on_failure):\n",
    "        path_length = len(path) - 1 if ends_on_failure else len(path)\n",
    "        n_probs[path_length] = prob if path_length not in n_probs else n_probs[path_length] + prob\n",
    "    sum_probs += prob\n",
    "print(f\"No. of Paths: {path_no}. Sum of Probabilities: {sum_probs} ({Fraction(sum_probs).limit_denominator()})\")\n",
    "n_probs[0] = sum(n_probs.values()) # TODO: Verify this\n",
    "print(\"\\n\".join(f\"{k} devices: {v}\" for k,v in sorted(n_probs.items(),key=lambda item: item[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = nx.adjacency_matrix(pcn.graph, nodelist=sorted(pcn.graph.nodes(), key=lambda node: node.id)).todense()\n",
    "print(\"A\\n\", A)\n",
    "np.fill_diagonal(A, val=0)\n",
    "A2 = A@A\n",
    "np.fill_diagonal(A2, val=0)\n",
    "print(\"A^2\\n\", A2)\n",
    "A3 = A2@A\n",
    "np.fill_diagonal(A3, val=0)\n",
    "print(\"A^3\\n\", A3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_required = 0.0\n",
    "nodes = pcn.graph.nodes()\n",
    "node_probs = {}\n",
    "for node in nodes:\n",
    "    # print(node)\n",
    "    probability_to_compromise = 1.0\n",
    "    for defence_name, defence in node.defences.items():\n",
    "        expected_effort = defence.effort_distribution.expect()\n",
    "        time_required += expected_effort\n",
    "        # print(\"\\t\", defence_name)\n",
    "        probability_to_compromise *= defence.p\n",
    "    node_probs[node] = probability_to_compromise\n",
    "\n",
    "prob_to_compromise_n_devices = {}\n",
    "all_nodes = set(nodes)\n",
    "cumulative = 0.0\n",
    "for n_devices in range(pcn.n_components, 0, -1):\n",
    "    prob_to_compromise_n_devices[n_devices] = cumulative\n",
    "    for combination in itertools.combinations(nodes, n_devices):\n",
    "        probability_to_compromise = 1.0\n",
    "        combination = set(combination)\n",
    "        missing_nodes = all_nodes.difference(combination)\n",
    "        for node in combination:\n",
    "            probability_to_compromise *= node_probs[node]\n",
    "        for node in missing_nodes:\n",
    "            probability_to_compromise *= (1 - node_probs[node])\n",
    "        prob_to_compromise_n_devices[n_devices] += probability_to_compromise \n",
    "    print(f\"{n_devices} Devices: {prob_to_compromise_n_devices[n_devices]}\")\n",
    "    cumulative += prob_to_compromise_n_devices[n_devices]\n",
    "print(prob_to_compromise_n_devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the probability of compromising all components is the same,\n",
    "# we can use the Binomial distribution function\n",
    "# Takes: 12.6 µs\n",
    "N = pcn.n_components\n",
    "k = 2\n",
    "p = 0.5\n",
    "cumulative = 0.0\n",
    "for k in range(pcn.n_components, 0, -1):\n",
    "    prob = math.comb(N, k)*math.pow(p, k)*math.pow(1-p,N-k)\n",
    "    print(f\"{k} Devices: {cumulative + prob}\")\n",
    "    cumulative += prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats.distributions as distr\n",
    "distr_lookup = {\n",
    "    \"TruncNorm\": distr.truncnorm, # Continuous, loc=mean (float), scale=standard deviation (float)\n",
    "    \"Exponential\": distr.expon, # Continuous, scale = 1 / lambda (float)\n",
    "    \"Gamma\": distr.gamma, # Continuous, a = shape parameter (integer)\n",
    "    \"Bernoulli\": distr.bernoulli, # Discrete\n",
    "}\n",
    "n_attacks = 20\n",
    "is_successful = distr.bernoulli(0.5).rvs(size=n_attacks).astype(bool)\n",
    "time_taken = distr.expon(scale=0.0).rvs(size=n_attacks)[is_successful]\n",
    "print(f\"Successful Attacks {sum(is_successful)}/{n_attacks}\\nTime Taken per Successful Attack: {time_taken}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Communication Network Specifications\n",
    "Explores how we can supply structured information to our procedural network generation algorithm. Includes information such as the types of components and defences we expect to see in the communication network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed = np.random.randint(low=0, high=52600)\n",
    "seed = 27194\n",
    "print(f\"Seed: {seed}\")\n",
    "np.random.seed(seed)\n",
    "pcn = CommNetwork(n_devices=15, n_entrypoints=1, children_per_parent=5, child_no_deviation=1,\n",
    "                  network_specs=\"SmartMeterNetworkSpecifications.json\",\n",
    "                  enable_sibling_to_sibling_comm=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criticality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandapower as pp\n",
    "import pandapower.networks as grids\n",
    "grid = pp.create_empty_network()\n",
    "grid_filter = lambda module: inspect.isfunction(module) and not module.__name__.startswith(\"_\")\n",
    "grid_map = {grid_name:grid_creator for grid_name, grid_creator in \\\n",
    "            inspect.getmembers(grids, predicate=grid_filter)}\n",
    "grid_options = list(grid_map.keys())\n",
    "print(\", \".join(grid_map.keys()))\n",
    "CHOSEN_GRID = \"mv_oberrhein\" # \"create_cigre_network_mv\" # Can be None\n",
    "kwargs = dict(scenario=\"generation\", include_substations=True) #  dict(with_der=\"all\")\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(action=\"ignore\", category=FutureWarning)\n",
    "    grid_name = np.random.choice(grid_options) if CHOSEN_GRID is None else CHOSEN_GRID\n",
    "    print(f\"Grid: {grid_name}\")\n",
    "    grid = grid_map[grid_name](**kwargs)\n",
    "    print(grid)\n",
    "    # Controllable\n",
    "    n_controllable = sum(getattr(grid, attr).shape[0] for attr in [\"gen\", \"shunt\", \"trafo\", \"switch\"])\n",
    "    print(f\"No. of controllable elements: {n_controllable} (generators, shunts, transformers and switches)\")\n",
    "    # Sensor-Only\n",
    "    n_sensor_only = sum(getattr(grid, attr).shape[0] for attr in [\"bus\", \"load\", \"line\"])\n",
    "    print(f\"No. of sensor-only elements: {n_sensor_only} (buses, loads and lines)\")\n",
    "    print(f\"Total (possible) no. of devices: {n_sensor_only+n_controllable} (generators, shunts, transformers and switches, buses, loads and lines)\")\n",
    "\n",
    "# grid.switch.closed = True\n",
    "pp.plotting.simple_plot(grid, respect_switches=True, plot_line_switches=True, plot_loads=True, plot_gens=True, plot_sgens=True, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import grid2op\n",
    "from network_specification import SpecDecoder\n",
    "\n",
    "def evaluate_grid2op_conditions(device_type:dict, obs:grid2op.Observation, obj_ids):\n",
    "    \"\"\"\n",
    "    Checks each object ID at a specific substation to see if it meets the conditions\n",
    "    given in the network's JSON specifications. \n",
    "\n",
    "    Returns:\n",
    "        list: IDs that satisfy the condition.\n",
    "    \"\"\"\n",
    "    conditions = device_type.get(\"conditions\", None)\n",
    "    device_ids = copy.deepcopy(obj_ids)\n",
    "    if conditions is not None and len(obj_ids) > 0:\n",
    "        for condition in conditions:\n",
    "            # TODO: Check this works for multiple conditions\n",
    "            values = getattr(obs, condition[\"attribute\"])[list(set(device_ids))]\n",
    "            match condition[\"action\"]:\n",
    "                case \"filter\":\n",
    "                    matching_ids = np.where((values >= condition.get(\"lb\", -math.inf)) & \\\n",
    "                                            (values < condition.get(\"ub\", math.inf)))\n",
    "                    device_ids = device_ids[matching_ids]\n",
    "                case \"split\":\n",
    "                    limit = condition.get(\"limit\", math.inf)\n",
    "                    ids_to_split = device_ids[np.where(values > limit)]\n",
    "                    \n",
    "                    new_ids = [obj_id for obj_id in device_ids if obj_id not in ids_to_split]\n",
    "                    for i, id_to_split in enumerate(ids_to_split):\n",
    "                        new_ids.extend([id_to_split]*math.ceil(values[i] / limit))\n",
    "                    device_ids = new_ids\n",
    "    return device_ids\n",
    "\n",
    "with open(p.cwd() / \"specifications\" / \"SmartMeter_specifications.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    specs = json.load(f, cls=SpecDecoder)\n",
    "\n",
    "device_types = specs[\"device\"][\"types\"]\n",
    "device_type_prob = specs[\"device\"].get(\"proportion\", [1/len(device_types)]*len(device_types))\n",
    "# Device Type is based on compatibility with power grid element in PandaPower\n",
    "compatabilities = {}\n",
    "for device_type in device_types:\n",
    "    compatible_devices = device_type.get(\"compatible\")\n",
    "    for compatible_device in compatible_devices:\n",
    "        if compatible_device not in compatabilities:\n",
    "            compatabilities[compatible_device] = [device_type]\n",
    "        else:\n",
    "            compatabilities[compatible_device] = compatabilities[compatible_device] + [device_type]\n",
    "\n",
    "# Map device type (by name) to probability that device is of that type\n",
    "probs = {device_type.get(\"name\"): prob for device_type, prob in zip(device_types, device_type_prob)}\n",
    "\n",
    "# Grid2Op Obj name mapping\n",
    "grid2op_naming = {\"load\": \"loads_id\", \"gen\":\"generators_id\", \"line\":\"lines_or_id\", \"storage\":\"storages_id\"}\n",
    "\n",
    "no_of_devices = 0\n",
    "device_map = {}\n",
    "for sub_no, sub_name in enumerate(env.name_sub):\n",
    "    connected_objs = env.get_obj_connect_to(substation_id=sub_no)\n",
    "    \n",
    "    for attr, compatible_device_types in compatabilities.items():\n",
    "        obj_ids = connected_objs[grid2op_naming[attr]]\n",
    "        print(f\"Substation: {obj_ids}\", end=\" \")\n",
    "        obj_ids = evaluate_grid2op_conditions(device_type, obs, obj_ids)\n",
    "        print(obj_ids)\n",
    "        no_of_attr_devices =len(obj_ids)\n",
    "        for i in range(no_of_devices, no_of_devices+no_of_attr_devices):\n",
    "            # Recalculate probability of choosing each compatible device\n",
    "            # Retains original proportion, probabilities must sum to 1\n",
    "            local_probs = np.array([probs[device_type.get(\"name\")] for device_type in compatible_device_types])\n",
    "            local_probs = (1/sum(local_probs))*local_probs\n",
    "            device_map[i] = np.random.choice(compatible_device_types, p=local_probs)\n",
    "        no_of_devices += no_of_attr_devices\n",
    "print(device_map.keys())\n",
    "device_map = device_map.items()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
