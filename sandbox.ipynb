{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import math\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats.distributions as distr\n",
    "\n",
    "from cyber import Defence, CommmonDefences, CyberComponent\n",
    "from tree import TreeNode, Link\n",
    "from comm_network import Aggregator, Device, CommNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from comm_network import LevelOfRedundancy\n",
    "seed = np.random.randint(low=0, high=52600)\n",
    "seed = 27194\n",
    "print(f\"Seed: {seed}\")\n",
    "np.random.seed(seed)\n",
    "pcn = CommNetwork(n_devices=3, n_entrypoints=3, redundancy=2, redundancy_deviation=1, enable_sibling_to_sibling_comm=True)\n",
    "root = pcn.root\n",
    "print(CommNetwork.show_tree(root))\n",
    "tree = pcn.graph\n",
    "print(f\"Number of Components: {pcn.n_components}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from attackers import RandomAttacker\n",
    "attacker = RandomAttacker(budget=52, verbose=True)\n",
    "attacker.attack_network(pcn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hierarchy_pos(G:nx.DiGraph, root:TreeNode, width:float=1., vert_gap:float=0.2, vert_loc:float=0, xcenter:float=0.5):\n",
    "\n",
    "    '''\n",
    "    Credit: Joel (https://stackoverflow.com/a/29597209/2966723) \n",
    "    Licensed under CC Attribution-Share Alike \n",
    "    \n",
    "    If the graph is a tree this will return the positions to plot this in a \n",
    "    hierarchical layout.\n",
    "    \n",
    "    G (networkx.DiGraph): Graph (must be a tree)\n",
    "    root (Node): Root node of current graph\n",
    "    width (float): Horizontal space allocated for this branch - avoids overlap with other branches. Defaults to 1.0\n",
    "    vert_gap (float): Gap between levels of hierarchy. Defaults to 0.2\n",
    "    vert_loc (float): Vertical location of root. Defaults to 0.0\n",
    "    xcenter (float): Horizontal location of root. Defaults to 0.5\n",
    "    '''\n",
    "    # if not nx.is_tree(G):\n",
    "    #     raise TypeError('cannot use hierarchy_pos on a graph that is not a tree')\n",
    "\n",
    "    if root is None:\n",
    "        if isinstance(G, nx.DiGraph):\n",
    "            root = next(iter(nx.topological_sort(G)))  #allows back compatibility with nx version 1.11\n",
    "        else:\n",
    "            root = np.random.choice(list(G.nodes))\n",
    "\n",
    "    def _hierarchy_pos(G, root, width=1., vert_gap = 0.2, vert_loc = 0, xcenter = 0.5, pos = None, parent = None):\n",
    "        '''\n",
    "        see hierarchy_pos docstring for most arguments\n",
    "\n",
    "        pos: a dict saying where all nodes go if they have been assigned\n",
    "        parent: parent of this branch. - only affects it if non-directed\n",
    "\n",
    "        '''\n",
    "    \n",
    "        if pos is None:\n",
    "            pos = {root:(xcenter,vert_loc)}\n",
    "        else:\n",
    "            pos[root] = (xcenter, vert_loc)\n",
    "        children = root.children # list(G.neighbors(root))\n",
    "        if not isinstance(G, nx.DiGraph) and parent is not None:\n",
    "            for child in children:\n",
    "                child.remove_parents(parent)  \n",
    "        if len(children) !=0:\n",
    "            dx = width/len(children) \n",
    "            nextx = xcenter - width/2 - dx/2\n",
    "            for child in sorted(children, key=lambda child:child.id):\n",
    "                nextx += dx\n",
    "                pos = _hierarchy_pos(G,child, width = dx, vert_gap = vert_gap, \n",
    "                                    vert_loc = vert_loc-vert_gap, xcenter=nextx,\n",
    "                                    pos=pos, parent = root)\n",
    "        return pos\n",
    "\n",
    "            \n",
    "    return _hierarchy_pos(G, root, width, vert_gap, vert_loc, xcenter)\n",
    "\n",
    "node_color_mask = np.full(tree.number_of_nodes(), fill_value=\"#1f78b4\", dtype=object)\n",
    "node_edge_color_mask = np.full(tree.number_of_nodes(), fill_value=\"#000000\", dtype=object)\n",
    "edge_color_mask = np.full(tree.number_of_edges(), fill_value=\"#000000\", dtype=object)\n",
    "node_shape_mask = np.full(tree.number_of_nodes(), fill_value=\"s\", dtype=object)\n",
    "root_idx = None\n",
    "for i, node in enumerate(tree.nodes()):\n",
    "    if node.is_leaf:\n",
    "        # Dark Green if the Leaf Node (Device) is an entry point\n",
    "        node_color_mask[i] = \"green\" if node.is_accessible else \"lightgreen\"\n",
    "    else:\n",
    "        # Dark Blue if the Internal Node (Aggregator) is an entry point\n",
    "        node_color_mask[i] = \"#1f78b4\" if node.is_accessible else \"#1f98ff\"\n",
    "    # If the Node has no parent, it is the root of the Tree (the control center)\n",
    "    if len(node.parents) == 0:\n",
    "        root_idx = i\n",
    "        node_color_mask[i] = \"coral\"\n",
    "    if node.is_compromised:\n",
    "        # Compromised/hacked nodes have a red outline around them\n",
    "        node_edge_color_mask[i] = \"#ff0000\"\n",
    "\n",
    "for j, (start_node, end_node) in enumerate(tree.edges()):\n",
    "    # Edges / Communication Channels between 2 compromised nodes are compromised\n",
    "    if start_node.is_compromised and end_node.is_compromised:\n",
    "        edge_color_mask[j] = \"#ff0000\"\n",
    "\n",
    "# >> Plotting <<\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2,  figsize=(24,6), width_ratios=[0.6, 0.4])\n",
    "label_map = {node:node.id for node in tree.nodes()}\n",
    "\n",
    "# Hierarchical / Tree Visualization of Communication Network\n",
    "tree_pos = hierarchy_pos(nx.to_undirected(tree), root)\n",
    "nx.draw_networkx_nodes(tree, pos=tree_pos, ax=axes[0],\n",
    "                       node_size=400, node_shape=\"s\", node_color=node_color_mask,\n",
    "                       linewidths=1.0, edgecolors=node_edge_color_mask)\n",
    "nx.draw_networkx_labels(tree, pos=tree_pos, labels=label_map, ax=axes[0], font_size=10)\n",
    "nx.draw_networkx_edges(tree, pos=tree_pos, ax=axes[0], edge_color=edge_color_mask)\n",
    "\n",
    "# Spring Visualization of Communication Network\n",
    "spring_pos = nx.layout.spring_layout(tree)\n",
    "nx.draw_networkx_nodes(tree, pos=spring_pos, ax=axes[1],\n",
    "                       node_size=400, node_shape=\"s\", node_color=node_color_mask, \n",
    "                       linewidths=1.0, edgecolors=node_edge_color_mask, )\n",
    "nx.draw_networkx_labels(tree, pos=spring_pos, labels=label_map, ax=axes[1], font_size=10)\n",
    "nx.draw_networkx_edges(tree, pos=spring_pos, ax=axes[1], edge_color=edge_color_mask)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = nx.adjacency_matrix(pcn.graph, nodelist=sorted(pcn.graph.nodes(), key=lambda node: node.id)).todense()\n",
    "print(\"A\\n\", A)\n",
    "np.fill_diagonal(A, val=0)\n",
    "A2 = A@A\n",
    "np.fill_diagonal(A2, val=0)\n",
    "print(\"A^2\\n\", A2)\n",
    "A3 = A2@A\n",
    "np.fill_diagonal(A3, val=0)\n",
    "print(\"A^3\\n\", A3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in pcn.graph.nodes():\n",
    "    print(node, \"\\n\\t\", [n for n in pcn.graph.neighbors(node)])\n",
    "    print(\"\\t\", [defence.p for defence in node.defences.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = []\n",
    "for node in pcn.graph.nodes():\n",
    "    neighbors = set([n for n in pcn.graph.neighbors(node)])\n",
    "    sets.append(neighbors)\n",
    "print([n.id for n in sets[1]], [n.id for n in sets[2]], [n.id for n in sets[3]], [n.id for n in sets[4]])\n",
    "print(sets[4].difference(sets[2]), [n.id for n in sets[4].difference(sets[2])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set([3, 5, 0, 4, 1]).difference(set([5, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def iter_paths(graph, path=None, prob_to_compromise=1.0, reachable_nodes=set(), visited_nodes=set()):\n",
    "    if not path:\n",
    "        # Different starting locations\n",
    "        for start_node in graph.nodes():\n",
    "            yield from iter_paths(graph, [start_node], 1.0)\n",
    "            break\n",
    "    else:\n",
    "        current_node = path[-1]\n",
    "        visited_previously = current_node in visited_nodes\n",
    "        if not visited_previously:\n",
    "            visited_nodes.add(current_node)\n",
    "        neighbouring_nodes = current_node.get_neighbours()\n",
    "        reachable_nodes = reachable_nodes | neighbouring_nodes\n",
    "        reachable_nodes = reachable_nodes - visited_nodes\n",
    "        # reachable_nodes = reachable_nodes - visited_nodes\n",
    "        if len(path) >= 1:\n",
    "            # Probability to not compromise the remaining reachable nodes\n",
    "            prob_not_compromised = np.prod([(1-node.get_prob_to_compromise()) for node in reachable_nodes])\n",
    "            # Probability that we compromised everything along the current path (so far)\n",
    "            prob_to_compromise *= current_node.get_prob_to_compromise()\n",
    "            print(\"Reachable Nodes:\", [n.id for n in reachable_nodes])\n",
    "            print(\"Visited Nodes:\", [n.id for n in visited_nodes])\n",
    "            yield path, prob_to_compromise*prob_not_compromised\n",
    "        if visited_previously:\n",
    "            return\n",
    "        for reachable_node in reachable_nodes:\n",
    "            yield from iter_paths(graph,\n",
    "                                  path+[reachable_node],\n",
    "                                  prob_to_compromise,\n",
    "                                  copy.copy(reachable_nodes), \n",
    "                                  copy.copy(visited_nodes))\n",
    "sum_probs = 0.0\n",
    "n_probs = {}\n",
    "for path_no, (path, prob) in enumerate(iter_paths(pcn.graph)):\n",
    "    print(f\"Path {path_no} :: Prob {str(prob):<15} :: {'-'.join([str(node.id) for node in path])}\")\n",
    "    n_probs[len(path)] = prob if len(path) not in n_probs else n_probs[len(path)] + prob\n",
    "    sum_probs += prob\n",
    "print(f\"No. of Paths: {path_no}. Sum of Probabilities: {sum_probs}\")\n",
    "print(\"\\n\".join(f\"{k} devices: {v}\" for k,v in n_probs.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_required = 0.0\n",
    "nodes = pcn.graph.nodes()\n",
    "node_probs = {}\n",
    "for node in nodes:\n",
    "    # print(node)\n",
    "    probability_to_compromise = 1.0\n",
    "    for defence_name, defence in node.defences.items():\n",
    "        expected_effort = defence.effort_distribution.expect()\n",
    "        time_required += expected_effort\n",
    "        # print(\"\\t\", defence_name)\n",
    "        probability_to_compromise *= defence.p\n",
    "    node_probs[node] = probability_to_compromise\n",
    "\n",
    "prob_to_compromise_n_devices = {}\n",
    "all_nodes = set(nodes)\n",
    "cumulative = 0.0\n",
    "for n_devices in range(pcn.n_components, 0, -1):\n",
    "    prob_to_compromise_n_devices[n_devices] = cumulative\n",
    "    for combination in itertools.combinations(nodes, n_devices):\n",
    "        probability_to_compromise = 1.0\n",
    "        combination = set(combination)\n",
    "        missing_nodes = all_nodes.difference(combination)\n",
    "        for node in combination:\n",
    "            probability_to_compromise *= node_probs[node]\n",
    "        for node in missing_nodes:\n",
    "            probability_to_compromise *= (1 - node_probs[node])\n",
    "        prob_to_compromise_n_devices[n_devices] += probability_to_compromise \n",
    "    print(f\"{n_devices} Devices: {prob_to_compromise_n_devices[n_devices]}\")\n",
    "    cumulative += prob_to_compromise_n_devices[n_devices]\n",
    "print(prob_to_compromise_n_devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "from multiprocessing import Process, Pool\n",
    "\n",
    "def combinations(iterable, k):\n",
    "    # combinations('ABCD', 2) --> AB AC AD BC BD CD\n",
    "    # combinations(range(4), 3) --> 012 013 023 123\n",
    "    pool = tuple(iterable)\n",
    "    n = len(pool)\n",
    "    if k > n:\n",
    "        return\n",
    "    indices = list(range(k))\n",
    "    yield tuple(pool[i] for i in indices), tuple(pool[i] for i in range(k, n)), k\n",
    "    while True:\n",
    "        for i in reversed(range(k)):\n",
    "            if indices[i] != i + n - k:\n",
    "                break\n",
    "        else:\n",
    "            return\n",
    "        indices[i] += 1\n",
    "        for j in range(i+1, k):\n",
    "            indices[j] = indices[j-1] + 1\n",
    "        neg_indices = tuple(pool[i] for i in range(n) if i not in indices)\n",
    "        yield tuple(pool[i] for i in indices), neg_indices, k\n",
    "\n",
    "def process_wrapper(successes, failures, k):\n",
    "    prob = np.prod(successes)\n",
    "    return prob + (np.prod(failures) if len(failures) >= 1 else 1.0), k\n",
    "\n",
    "N = pcn.n_components\n",
    "p = 0.5\n",
    "np.random.seed(0)\n",
    "ps = np.random.uniform(low=0, high=1, size=N)\n",
    "ps = np.full(shape=N, fill_value=p)\n",
    "idcs = np.arange(N)\n",
    "all_idcs = set(idcs)\n",
    "cumulative = 0.0\n",
    "with Pool(processes=mp.cpu_count()-1) as pool:\n",
    "    results = []\n",
    "    for k in range(pcn.n_components, 0, -1):\n",
    "        # k_prob = 0.0\n",
    "        results.extend(pool.imap_unordered(process_wrapper, combinations(ps, k), chunksize=32))\n",
    "print(\"Pool Active\")\n",
    "[result.wait() for result in results]\n",
    "            # results = [pool.apply_async(process_wrapper, args=(successes, failures)) for successes, failures in combinations(ps, k)]\n",
    "            # k_prob = sum([res.get(timeout=-1) for res in results])\n",
    "                # # Succeses: p^k (where p is not fixed)\n",
    "                # prob = np.prod(successes)\n",
    "                # # Failures: (1-p)^(n-k) (where p is not fixed)\n",
    "                # prob *= np.prod(failures) if len(failures) >= 1 else 1.0\n",
    "            # k_prob += prob\n",
    "        # print(f\"{k}: {cumulative + k_prob}, {k_prob}\")\n",
    "        # cumulative += k_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the probability of compromising all components is the same,\n",
    "# we can use the Binomial distribution function\n",
    "# Takes: 12.6 µs\n",
    "N = pcn.n_components\n",
    "k = 2\n",
    "p = 0.5\n",
    "cumulative = 0.0\n",
    "for k in range(pcn.n_components, 0, -1):\n",
    "    prob = math.comb(N, k)*math.pow(p, k)*math.pow(1-p,N-k)\n",
    "    print(f\"{k} Devices: {cumulative + prob}\")\n",
    "    cumulative += prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.comb(5,3)*math.pow(0.5,3)*math.pow(0.5, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats.distributions as distr\n",
    "distr_lookup = {\n",
    "    \"TruncNorm\": distr.truncnorm, # Continuous, loc=mean (float), scale=standard deviation (float)\n",
    "    \"Exponential\": distr.expon, # Continuous, scale = 1 / lambda (float)\n",
    "    \"Gamma\": distr.gamma, # Continuous, a = shape parameter (integer)\n",
    "    \"Bernoulli\": distr.bernoulli, # Discrete\n",
    "}\n",
    "n_attacks = 20\n",
    "is_successful = distr.bernoulli(0.5).rvs(size=n_attacks).astype(bool)\n",
    "time_taken = distr.expon(scale=0.0).rvs(size=n_attacks)[is_successful]\n",
    "print(f\"Successful Attacks {sum(is_successful)}/{n_attacks}\\nTime Taken per Successful Attack: {time_taken}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
